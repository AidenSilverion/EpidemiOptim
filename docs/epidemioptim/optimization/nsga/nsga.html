<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.1" />
<title>epidemioptim.optimization.nsga.nsga API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>epidemioptim.optimization.nsga.nsga</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import os

import pickle
import numpy as np
from pymoo.model.problem import Problem
from pymoo.algorithms.nsga2 import NSGA2
from pymoo.optimize import minimize
from pymoo.visualization.scatter import Scatter
from pymoo.model.sampling import Sampling
from sklearn.neighbors import NearestNeighbors
from pymoo.configuration import Configuration
Configuration.show_compile_hint = False

from epidemioptim.optimization.shared.rollout import run_rollout
from epidemioptim.optimization.base_algorithm import BaseAlgorithm
from epidemioptim.optimization.shared.networks import QNetFC
from epidemioptim.utils import compute_pareto_front


def create_problem(n_params, n_objs, runner):
    class NSGAProblem(Problem):
        &#34;&#34;&#34;
        Defines a problem for the pymoo library
        &#34;&#34;&#34;
        def __init__(self, nb_params, nb_objs):
            super().__init__(n_var=nb_params, n_obj=nb_objs, n_constr=0, xl=-1, xu=1)

        def _evaluate(self, x, out, *args, **kwargs):
            out[&#34;F&#34;], out[&#34;F_std&#34;] = runner(x)
            return out

    return NSGAProblem(n_params, n_objs)


class NSGAII(BaseAlgorithm):
    def __init__(self, env, params):
        &#34;&#34;&#34;
        NSGA-II Algorithm based on the implementation in the Pymoo library.

        Parameters
        ----------
        env: BaseEnv
            The learning environment.
        params: dict
            All experiment params

         Attributes
        ----------
        layers: tuple of ints
            Describes sizes of hidden layers of the critics.
        logdir: str
            Logging directory
        eval_and_log_every: int
            Frequency to pring logs (in episodes).
        n_evals_if_stochastic: int
            Number of evaluation episodes if the environment is stochastic.
        stochastic: bool
            Whether the environment is stochastic.
        dims: dict
            Dimensions of states and actions.
        cost_function: BaseMultiCostFunction
            Multi-cost function.
        nb_costs: int
            Number of cost functions

        &#34;&#34;&#34;

        super(NSGAII, self).__init__(env, params)

        # Save parameters
        self.is_multi_obj = True  # NSGA-II is a multi-obj algorithm
        self.logdir = params[&#39;logdir&#39;]
        self.log_every = self.algo_params[&#39;eval_and_log_every&#39;]
        self.seed = params[&#39;seed&#39;]
        self.popsize = self.algo_params[&#39;popsize&#39;]  # size of NSGA population
        self.layers = tuple(self.algo_params[&#39;layers&#39;])
        self.nb_gens = self.algo_params[&#39;nb_gens&#39;]  # number of generations to run NSGA.
        self.stochastic = params[&#39;model_params&#39;][&#39;stochastic&#39;]
        self.n_evals_if_stochastic = self.algo_params[&#39;n_evals_if_stochastic&#39;]
        self.dims = dict(s=env.observation_space.shape[0],
                         a=env.action_space.n)
        self.nb_costs = self.env.unwrapped.cost_function.nb_costs
        self.cost_function = self.env.unwrapped.cost_function

        if self.logdir:
            os.makedirs(self.logdir + &#39;models/&#39;, exist_ok=True)

        # Create policy
        self.policy = QNetFC(dim_state=self.dims[&#39;s&#39;],
                             dim_goal=0,
                             dim_actions=self.dims[&#39;a&#39;],
                             layers=self.layers,
                             goal_ids=())
        self.dim_params = self.policy.nb_params

        # Sample initial weights just like pytorch would do.
        dims = self.dims
        layers = self.layers
        class NNSampling(Sampling):
            def __init__(self, var_type=np.float) -&gt; None:
                super().__init__()
                self.var_type = var_type

            def _do(self, problem, n_samples, **kwargs):
                # val = np.random.random((n_samples, problem.n_var))
                val = []
                for _ in range(n_samples):
                    policy = QNetFC(dim_state=dims[&#39;s&#39;],
                                    dim_goal=0,
                                    dim_actions=dims[&#39;a&#39;],
                                    layers=layers,
                                    goal_ids=[])
                    params = policy.get_params()
                    val.append(params)
                return np.array(val)

        # Initialize counters
        self.learn_step_counter = 0
        self.env_step_counter = 0
        self.episode = 0
        self.history = []
        self.res = None

        # define rollout function for nsga
        def runner(x):
            costs_mean = []
            costs_std = []
            for i in range(x.shape[0]):
                self.policy.set_params(x[i])
                episodes = run_rollout(policy=self,
                                       env=self.env,
                                       n=self.n_evals_if_stochastic if self.stochastic else 1,
                                       eval=False,
                                       additional_keys=[&#39;costs&#39;, &#39;n_icu&#39;],
                                       )
                costs_eps = np.array([np.sum(episodes[i_ep][&#39;costs&#39;], axis=0) for i_ep in range(self.n_evals_if_stochastic if self.stochastic else 1)])
                costs_mean.append(costs_eps.mean(axis=0))
                costs_std.append(costs_eps.std(axis=0))

            return np.array(costs_mean), np.array(costs_std)

        # Create problem for pymoo
        self.nsga_problem = create_problem(n_params=self.dim_params,
                                           n_objs = self.nb_costs,
                                           runner=runner)

        if self.algo_params[&#39;policy&#39;] == &#39;nn&#39;:
            self.algorithm = NSGA2(pop_size=self.popsize,
                                   sampling=NNSampling())
        else:
            self.algorithm = NSGA2(pop_size=self.popsize)

    def act(self, state, deterministic=False):
        &#34;&#34;&#34;
        Policy that uses the learned critics.

        Parameters
        ----------
        state: 1D nd.array
            Current state.
        deterministic: bool
            Whether the policy should be deterministic (e.g. in evaluation mode).

        Returns
        -------
        action: nd.array
            Action vector.
        &#34;&#34;&#34;
        return self.policy.act(state), None


    def learn(self, num_train_steps):
        &#34;&#34;&#34;
        Main training loop.

        Parameters
        ----------
        num_train_steps: int
            Number of training steps (environment steps)

        Returns
        -------

        &#34;&#34;&#34;
        self.res_run = minimize(problem=self.nsga_problem,
                            algorithm=self.algorithm,
                            termination=(&#39;n_gen&#39;, self.nb_gens),
                            verbose=True,
                            seed=self.seed,
                            save_history=True)
        self.res_eval = self.evaluate(n=self.n_evals_if_stochastic if self.stochastic else 1, all=True)
        F_std = self.res_run.algorithm.opt.get(&#34;F_std&#34;)
        self.res_run.F_std = F_std

        self.history = self.res_run.history
        self.log(res_eval)


    def evaluate(self, n=None, all=False, best=False, goal=None, reset_same_model=False):
        res = dict()

        if all:
            costs_mean = []
            costs_std = []
            for w in self.res.X:
                self.policy.set_params(w)
                episodes = run_rollout(policy=self,
                                       env=self.env,
                                       n=n,
                                       eval=True,
                                       reset_same_model=reset_same_model,
                                       additional_keys=[&#39;costs&#39;],
                                       )

                costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
                costs_mean.append(costs.mean(axis=0))
                costs_std.append(costs.std(axis=0))

            front_ids = compute_pareto_front(costs_mean)
            costs_mean = np.array(costs_mean)
            costs_std = np.array(costs_std)
            costs_std = costs_std[front_ids]
            costs_mean = costs_mean[front_ids]
            weights = self.res.X[front_ids]
            res[&#39;F&#39;] = costs_mean
            res[&#39;F_std&#39;] = costs_std
            res[&#39;X&#39;] = weights
            costs = costs_mean
        elif best:
            weights = self.res_eval[&#39;X&#39;]
            costs = self.res_eval[&#39;F&#39;]
            normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
            agg_cost = normalized_costs.sum(axis=1)
            ind_min = np.argmin(agg_cost)
            self.policy.set_params(weights[ind_min])
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            # res[&#39;X&#39;] = weights[ind_min]
            for i, c_m, c_std in zip(range(costs.shape[1]), costs.mean(axis=0), costs.std(axis=0)):
                res[&#39;C{} mean&#39;.format(i)] = c_m
                res[&#39;C{} std&#39;.format(i)] = c_std

        elif goal is not None:
            nn_model = NearestNeighbors(n_neighbors=1)

            weights = self.res_eval[&#39;X&#39;]
            costs = self.res_eval[&#39;F&#39;]
            normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
            nn_model.fit(normalized_costs)
            normalized_goal = np.atleast_2d(np.array([c_f.scale(g) for c_f, g in zip(self.cost_function.costs, goal)]))
            ind_nn = nn_model.kneighbors(normalized_goal, return_distance=False).flatten()
            self.policy.set_params(weights[ind_nn].flatten())
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            res[&#39;X&#39;] = weights[ind_nn]
            res[&#39;F&#39;] = costs.mean(axis=0)
            res[&#39;F_std&#39;] = costs.std(axis=0)
        else:
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            for i, c_m, c_std in zip(range(costs.shape[1]), costs.mean(axis=0), costs.std(axis=0)):
                res[&#39;C{} mean&#39;.format(i)] = c_m
                res[&#39;C{} std&#39;.format(i)] = c_std

        return res, costs



    def load_model(self, path):
        with open(path, &#39;rb&#39;) as f:
            self.res_eval = pickle.load(f)

        weights = self.res_eval[&#39;X&#39;]
        costs = self.res_eval[&#39;F&#39;]
        normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
        agg_cost = normalized_costs.sum(axis=1)
        ind_min = np.argmin(agg_cost)
        self.policy.set_params(weights[ind_min])

    def log(self, res_eval):

        self.res.problem = None
        for h in self.res_run.history:
            h.problem = None
            h.initialization = None
        self.res_run.algorithm.problem = None
        self.res_run.algorithm.initialization.sampling = None
        with open(self.logdir + &#39;res_train.pk&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.res_run, f)

        with open(self.logdir + &#39;res_eval.pk&#39;, &#39;wb&#39;) as f:
            pickle.dump(res_eval, f)
        print(&#39;Run has terminated successfully&#39;)

        plot = Scatter()
        plot.add(res_eval[&#39;F&#39;], color=&#34;red&#34;)
        plot.show()</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-functions">Functions</h2>
<dl>
<dt id="epidemioptim.optimization.nsga.nsga.create_problem"><code class="name flex">
<span>def <span class="ident">create_problem</span></span>(<span>n_params, n_objs, runner)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def create_problem(n_params, n_objs, runner):
    class NSGAProblem(Problem):
        &#34;&#34;&#34;
        Defines a problem for the pymoo library
        &#34;&#34;&#34;
        def __init__(self, nb_params, nb_objs):
            super().__init__(n_var=nb_params, n_obj=nb_objs, n_constr=0, xl=-1, xu=1)

        def _evaluate(self, x, out, *args, **kwargs):
            out[&#34;F&#34;], out[&#34;F_std&#34;] = runner(x)
            return out

    return NSGAProblem(n_params, n_objs)</code></pre>
</details>
</dd>
</dl>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="epidemioptim.optimization.nsga.nsga.NSGAII"><code class="flex name class">
<span>class <span class="ident">NSGAII</span></span>
<span>(</span><span>env, params)</span>
</code></dt>
<dd>
<div class="desc"><p>Helper class that provides a standard way to create an ABC using
inheritance.</p>
<p>NSGA-II Algorithm based on the implementation in the Pymoo library.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>env</code></strong> :&ensp;<code>BaseEnv</code></dt>
<dd>The learning environment.</dd>
<dt><strong><code>params</code></strong> :&ensp;<code>dict</code></dt>
<dd>All experiment params</dd>
</dl>
<h2 id="attributes">Attributes</h2>
<p>layers: tuple of ints
Describes sizes of hidden layers of the critics.
logdir: str
Logging directory
eval_and_log_every: int
Frequency to pring logs (in episodes).
n_evals_if_stochastic: int
Number of evaluation episodes if the environment is stochastic.
stochastic: bool
Whether the environment is stochastic.
dims: dict
Dimensions of states and actions.
cost_function: BaseMultiCostFunction
Multi-cost function.
nb_costs: int
Number of cost functions</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class NSGAII(BaseAlgorithm):
    def __init__(self, env, params):
        &#34;&#34;&#34;
        NSGA-II Algorithm based on the implementation in the Pymoo library.

        Parameters
        ----------
        env: BaseEnv
            The learning environment.
        params: dict
            All experiment params

         Attributes
        ----------
        layers: tuple of ints
            Describes sizes of hidden layers of the critics.
        logdir: str
            Logging directory
        eval_and_log_every: int
            Frequency to pring logs (in episodes).
        n_evals_if_stochastic: int
            Number of evaluation episodes if the environment is stochastic.
        stochastic: bool
            Whether the environment is stochastic.
        dims: dict
            Dimensions of states and actions.
        cost_function: BaseMultiCostFunction
            Multi-cost function.
        nb_costs: int
            Number of cost functions

        &#34;&#34;&#34;

        super(NSGAII, self).__init__(env, params)

        # Save parameters
        self.is_multi_obj = True  # NSGA-II is a multi-obj algorithm
        self.logdir = params[&#39;logdir&#39;]
        self.log_every = self.algo_params[&#39;eval_and_log_every&#39;]
        self.seed = params[&#39;seed&#39;]
        self.popsize = self.algo_params[&#39;popsize&#39;]  # size of NSGA population
        self.layers = tuple(self.algo_params[&#39;layers&#39;])
        self.nb_gens = self.algo_params[&#39;nb_gens&#39;]  # number of generations to run NSGA.
        self.stochastic = params[&#39;model_params&#39;][&#39;stochastic&#39;]
        self.n_evals_if_stochastic = self.algo_params[&#39;n_evals_if_stochastic&#39;]
        self.dims = dict(s=env.observation_space.shape[0],
                         a=env.action_space.n)
        self.nb_costs = self.env.unwrapped.cost_function.nb_costs
        self.cost_function = self.env.unwrapped.cost_function

        if self.logdir:
            os.makedirs(self.logdir + &#39;models/&#39;, exist_ok=True)

        # Create policy
        self.policy = QNetFC(dim_state=self.dims[&#39;s&#39;],
                             dim_goal=0,
                             dim_actions=self.dims[&#39;a&#39;],
                             layers=self.layers,
                             goal_ids=())
        self.dim_params = self.policy.nb_params

        # Sample initial weights just like pytorch would do.
        dims = self.dims
        layers = self.layers
        class NNSampling(Sampling):
            def __init__(self, var_type=np.float) -&gt; None:
                super().__init__()
                self.var_type = var_type

            def _do(self, problem, n_samples, **kwargs):
                # val = np.random.random((n_samples, problem.n_var))
                val = []
                for _ in range(n_samples):
                    policy = QNetFC(dim_state=dims[&#39;s&#39;],
                                    dim_goal=0,
                                    dim_actions=dims[&#39;a&#39;],
                                    layers=layers,
                                    goal_ids=[])
                    params = policy.get_params()
                    val.append(params)
                return np.array(val)

        # Initialize counters
        self.learn_step_counter = 0
        self.env_step_counter = 0
        self.episode = 0
        self.history = []
        self.res = None

        # define rollout function for nsga
        def runner(x):
            costs_mean = []
            costs_std = []
            for i in range(x.shape[0]):
                self.policy.set_params(x[i])
                episodes = run_rollout(policy=self,
                                       env=self.env,
                                       n=self.n_evals_if_stochastic if self.stochastic else 1,
                                       eval=False,
                                       additional_keys=[&#39;costs&#39;, &#39;n_icu&#39;],
                                       )
                costs_eps = np.array([np.sum(episodes[i_ep][&#39;costs&#39;], axis=0) for i_ep in range(self.n_evals_if_stochastic if self.stochastic else 1)])
                costs_mean.append(costs_eps.mean(axis=0))
                costs_std.append(costs_eps.std(axis=0))

            return np.array(costs_mean), np.array(costs_std)

        # Create problem for pymoo
        self.nsga_problem = create_problem(n_params=self.dim_params,
                                           n_objs = self.nb_costs,
                                           runner=runner)

        if self.algo_params[&#39;policy&#39;] == &#39;nn&#39;:
            self.algorithm = NSGA2(pop_size=self.popsize,
                                   sampling=NNSampling())
        else:
            self.algorithm = NSGA2(pop_size=self.popsize)

    def act(self, state, deterministic=False):
        &#34;&#34;&#34;
        Policy that uses the learned critics.

        Parameters
        ----------
        state: 1D nd.array
            Current state.
        deterministic: bool
            Whether the policy should be deterministic (e.g. in evaluation mode).

        Returns
        -------
        action: nd.array
            Action vector.
        &#34;&#34;&#34;
        return self.policy.act(state), None


    def learn(self, num_train_steps):
        &#34;&#34;&#34;
        Main training loop.

        Parameters
        ----------
        num_train_steps: int
            Number of training steps (environment steps)

        Returns
        -------

        &#34;&#34;&#34;
        self.res_run = minimize(problem=self.nsga_problem,
                            algorithm=self.algorithm,
                            termination=(&#39;n_gen&#39;, self.nb_gens),
                            verbose=True,
                            seed=self.seed,
                            save_history=True)
        self.res_eval = self.evaluate(n=self.n_evals_if_stochastic if self.stochastic else 1, all=True)
        F_std = self.res_run.algorithm.opt.get(&#34;F_std&#34;)
        self.res_run.F_std = F_std

        self.history = self.res_run.history
        self.log(res_eval)


    def evaluate(self, n=None, all=False, best=False, goal=None, reset_same_model=False):
        res = dict()

        if all:
            costs_mean = []
            costs_std = []
            for w in self.res.X:
                self.policy.set_params(w)
                episodes = run_rollout(policy=self,
                                       env=self.env,
                                       n=n,
                                       eval=True,
                                       reset_same_model=reset_same_model,
                                       additional_keys=[&#39;costs&#39;],
                                       )

                costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
                costs_mean.append(costs.mean(axis=0))
                costs_std.append(costs.std(axis=0))

            front_ids = compute_pareto_front(costs_mean)
            costs_mean = np.array(costs_mean)
            costs_std = np.array(costs_std)
            costs_std = costs_std[front_ids]
            costs_mean = costs_mean[front_ids]
            weights = self.res.X[front_ids]
            res[&#39;F&#39;] = costs_mean
            res[&#39;F_std&#39;] = costs_std
            res[&#39;X&#39;] = weights
            costs = costs_mean
        elif best:
            weights = self.res_eval[&#39;X&#39;]
            costs = self.res_eval[&#39;F&#39;]
            normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
            agg_cost = normalized_costs.sum(axis=1)
            ind_min = np.argmin(agg_cost)
            self.policy.set_params(weights[ind_min])
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            # res[&#39;X&#39;] = weights[ind_min]
            for i, c_m, c_std in zip(range(costs.shape[1]), costs.mean(axis=0), costs.std(axis=0)):
                res[&#39;C{} mean&#39;.format(i)] = c_m
                res[&#39;C{} std&#39;.format(i)] = c_std

        elif goal is not None:
            nn_model = NearestNeighbors(n_neighbors=1)

            weights = self.res_eval[&#39;X&#39;]
            costs = self.res_eval[&#39;F&#39;]
            normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
            nn_model.fit(normalized_costs)
            normalized_goal = np.atleast_2d(np.array([c_f.scale(g) for c_f, g in zip(self.cost_function.costs, goal)]))
            ind_nn = nn_model.kneighbors(normalized_goal, return_distance=False).flatten()
            self.policy.set_params(weights[ind_nn].flatten())
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            res[&#39;X&#39;] = weights[ind_nn]
            res[&#39;F&#39;] = costs.mean(axis=0)
            res[&#39;F_std&#39;] = costs.std(axis=0)
        else:
            episodes = run_rollout(policy=self,
                                   env=self.env,
                                   n=n,
                                   eval=True,
                                   additional_keys=[&#39;costs&#39;],
                                   )
            costs = np.array([np.array(e[&#39;costs&#39;]).sum(axis=0) for e in episodes])
            for i, c_m, c_std in zip(range(costs.shape[1]), costs.mean(axis=0), costs.std(axis=0)):
                res[&#39;C{} mean&#39;.format(i)] = c_m
                res[&#39;C{} std&#39;.format(i)] = c_std

        return res, costs



    def load_model(self, path):
        with open(path, &#39;rb&#39;) as f:
            self.res_eval = pickle.load(f)

        weights = self.res_eval[&#39;X&#39;]
        costs = self.res_eval[&#39;F&#39;]
        normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
        agg_cost = normalized_costs.sum(axis=1)
        ind_min = np.argmin(agg_cost)
        self.policy.set_params(weights[ind_min])

    def log(self, res_eval):

        self.res.problem = None
        for h in self.res_run.history:
            h.problem = None
            h.initialization = None
        self.res_run.algorithm.problem = None
        self.res_run.algorithm.initialization.sampling = None
        with open(self.logdir + &#39;res_train.pk&#39;, &#39;wb&#39;) as f:
            pickle.dump(self.res_run, f)

        with open(self.logdir + &#39;res_eval.pk&#39;, &#39;wb&#39;) as f:
            pickle.dump(res_eval, f)
        print(&#39;Run has terminated successfully&#39;)

        plot = Scatter()
        plot.add(res_eval[&#39;F&#39;], color=&#34;red&#34;)
        plot.show()</code></pre>
</details>
<h3>Ancestors</h3>
<ul class="hlist">
<li><a title="epidemioptim.optimization.base_algorithm.BaseAlgorithm" href="../base_algorithm.html#epidemioptim.optimization.base_algorithm.BaseAlgorithm">BaseAlgorithm</a></li>
<li>abc.ABC</li>
</ul>
<h3>Methods</h3>
<dl>
<dt id="epidemioptim.optimization.nsga.nsga.NSGAII.learn"><code class="name flex">
<span>def <span class="ident">learn</span></span>(<span>self, num_train_steps)</span>
</code></dt>
<dd>
<div class="desc"><p>Main training loop.</p>
<h2 id="parameters">Parameters</h2>
<dl>
<dt><strong><code>num_train_steps</code></strong> :&ensp;<code>int</code></dt>
<dd>Number of training steps (environment steps)</dd>
</dl>
<h2 id="returns">Returns</h2></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def learn(self, num_train_steps):
    &#34;&#34;&#34;
    Main training loop.

    Parameters
    ----------
    num_train_steps: int
        Number of training steps (environment steps)

    Returns
    -------

    &#34;&#34;&#34;
    self.res_run = minimize(problem=self.nsga_problem,
                        algorithm=self.algorithm,
                        termination=(&#39;n_gen&#39;, self.nb_gens),
                        verbose=True,
                        seed=self.seed,
                        save_history=True)
    self.res_eval = self.evaluate(n=self.n_evals_if_stochastic if self.stochastic else 1, all=True)
    F_std = self.res_run.algorithm.opt.get(&#34;F_std&#34;)
    self.res_run.F_std = F_std

    self.history = self.res_run.history
    self.log(res_eval)</code></pre>
</details>
</dd>
<dt id="epidemioptim.optimization.nsga.nsga.NSGAII.load_model"><code class="name flex">
<span>def <span class="ident">load_model</span></span>(<span>self, path)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def load_model(self, path):
    with open(path, &#39;rb&#39;) as f:
        self.res_eval = pickle.load(f)

    weights = self.res_eval[&#39;X&#39;]
    costs = self.res_eval[&#39;F&#39;]
    normalized_costs = np.array([c_f.scale(c) for c_f, c in zip(self.cost_function.costs, costs.transpose())]).transpose()
    agg_cost = normalized_costs.sum(axis=1)
    ind_min = np.argmin(agg_cost)
    self.policy.set_params(weights[ind_min])</code></pre>
</details>
</dd>
</dl>
<h3>Inherited members</h3>
<ul class="hlist">
<li><code><b><a title="epidemioptim.optimization.base_algorithm.BaseAlgorithm" href="../base_algorithm.html#epidemioptim.optimization.base_algorithm.BaseAlgorithm">BaseAlgorithm</a></b></code>:
<ul class="hlist">
<li><code><a title="epidemioptim.optimization.base_algorithm.BaseAlgorithm.act" href="../base_algorithm.html#epidemioptim.optimization.base_algorithm.BaseAlgorithm.act">act</a></code></li>
<li><code><a title="epidemioptim.optimization.base_algorithm.BaseAlgorithm.evaluate" href="../base_algorithm.html#epidemioptim.optimization.base_algorithm.BaseAlgorithm.evaluate">evaluate</a></code></li>
<li><code><a title="epidemioptim.optimization.base_algorithm.BaseAlgorithm.log" href="../base_algorithm.html#epidemioptim.optimization.base_algorithm.BaseAlgorithm.log">log</a></code></li>
</ul>
</li>
</ul>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="epidemioptim.optimization.nsga" href="index.html">epidemioptim.optimization.nsga</a></code></li>
</ul>
</li>
<li><h3><a href="#header-functions">Functions</a></h3>
<ul class="">
<li><code><a title="epidemioptim.optimization.nsga.nsga.create_problem" href="#epidemioptim.optimization.nsga.nsga.create_problem">create_problem</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="epidemioptim.optimization.nsga.nsga.NSGAII" href="#epidemioptim.optimization.nsga.nsga.NSGAII">NSGAII</a></code></h4>
<ul class="">
<li><code><a title="epidemioptim.optimization.nsga.nsga.NSGAII.learn" href="#epidemioptim.optimization.nsga.nsga.NSGAII.learn">learn</a></code></li>
<li><code><a title="epidemioptim.optimization.nsga.nsga.NSGAII.load_model" href="#epidemioptim.optimization.nsga.nsga.NSGAII.load_model">load_model</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.1</a>.</p>
</footer>
</body>
</html>